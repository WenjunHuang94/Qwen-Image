import time
from diffusers import DiffusionPipeline
import torch

# è®°å½•å¼€å§‹æ—¶é—´
start_time = time.time()

model_name = "Qwen/Qwen-Image"
# 1. åœ¨è¿™é‡Œå†™æ­»ä½ çš„ç¼“å­˜è·¯å¾„
my_cache_path = "/home/disk2/hwj/my_hf_cache"

# åŠ è½½ pipeline
if torch.cuda.is_available():
    print("CUDA is available. Using bfloat16 on GPU.")
    torch_dtype = torch.bfloat16
    device = "cuda"
else:
    print("CUDA not available. Using float32 on CPU.")
    torch_dtype = torch.float32
    device = "cpu"

pipe = DiffusionPipeline.from_pretrained(model_name, torch_dtype=torch_dtype)
pipe = pipe.to(device)

positive_magic = {
    "en": ", Ultra HD, 4K, cinematic composition.", # for english prompt
    "zh": ", è¶…æ¸…ï¼Œ4Kï¼Œç”µå½±çº§æ„å›¾." # for chinese prompt
}

# ç”Ÿæˆå›¾åƒ
# prompt = '''A coffee shop entrance features a chalkboard sign reading "Qwen Coffee ğŸ˜Š $2 per cup," with a neon light beside it displaying "é€šä¹‰åƒé—®". Next to it hangs a poster showing a beautiful Chinese woman, and beneath the poster is written "Ï€â‰ˆ3.1415926-53589793-23846264-33832795-02384197".'''
prompt = '''ohwhwj man, wearing a red helmet and orange life jacket, smiling with water droplets on his face.'''


negative_prompt = " " # Recommended if you don't use a negative prompt.

# é€‰æ‹©ä¸€ä¸ªå®½é«˜æ¯”
# width, height = (1024, 1024) # 16:9
width, height = (512, 512) # 16:9

print("Starting image generation... (This may take a moment)")

image = pipe(
    prompt=prompt + positive_magic["en"],
    negative_prompt=negative_prompt,
    width=width,
    height=height,
    num_inference_steps=50,
    true_cfg_scale=4.0,
    generator=torch.Generator(device="cuda").manual_seed(42)
).images[0]

image.save("example2.png")

# è®°å½•ç»“æŸæ—¶é—´å¹¶è®¡ç®—æ€»è€—æ—¶
end_time = time.time()
total_time = end_time - start_time

print(f"Image saved as example.png")
print(f"æ€»è€—æ—¶: {total_time:.2f} ç§’ ({total_time/60:.2f} åˆ†é’Ÿ)")