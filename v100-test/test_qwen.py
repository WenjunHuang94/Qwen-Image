import os
import torch
import numpy as np
from diffusers import DiffusionPipeline

# 1. æ˜¾å¡é…ç½®
os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2,3"

# 2. è·¯å¾„
local_model_path = "/storage/v-jinpewang/az_workspace/wenjun/Qwen-Image2/my_hf_cache/Qwen-Image/"

# æ˜¾å­˜åˆ†é…
max_memory_config = {
    0: "20GB",
    1: "30GB",
    2: "30GB",
    3: "30GB",
}

print("ğŸ› ï¸ æ­£åœ¨åŠ è½½æ¨¡å‹è¿›è¡Œæ•…éšœè¯Šæ–­ (FP16)...")

# åŠ è½½ Pipeline
pipe = DiffusionPipeline.from_pretrained(
    local_model_path,
    torch_dtype=torch.float16,  # ä¿æŒ FP16 ä»¥å¤ç°é—®é¢˜
    device_map="balanced",
    max_memory=max_memory_config,
    use_safetensors=True,
    local_files_only=True,
    trust_remote_code=True
)


# è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥ Tensor æ˜¯å¦æ­£å¸¸
def check_tensor(name, tensor):
    if tensor is None:
        return
    # è½¬ä¸º float32 è®¡ç®—ç»Ÿè®¡é‡ï¼Œé˜²æ­¢ç»Ÿè®¡æ—¶æº¢å‡º
    t_float = tensor.float()
    max_val = t_float.max().item()
    min_val = t_float.min().item()
    has_nan = torch.isnan(tensor).any().item()
    has_inf = torch.isinf(tensor).any().item()

    status = "âœ… æ­£å¸¸"
    if has_nan or has_inf:
        status = "âŒ æº¢å‡º (NaN/Inf)"
    elif abs(max_val) > 60000:  # æ¥è¿‘ FP16 ä¸Šé™
        status = "âš ï¸ å±é™© (æ¥è¿‘ FP16 ä¸Šé™)"

    print(f"[{name}] çŠ¶æ€: {status} | Max: {max_val:.2f} | Min: {min_val:.2f}")
    return has_nan or has_inf


# ==============================================================================
# ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥ Text Encoder (æ–‡æœ¬ç¼–ç å™¨)
# ==============================================================================
print("\nğŸ” æ­¥éª¤ 1: æ£€æŸ¥ Text Encoder è¾“å‡º...")
prompt = "A cute cat"
try:
    # æ‰‹åŠ¨è°ƒç”¨ encode_prompt
    prompt_embeds, prompt_masks = pipe.encode_prompt(
        prompt=prompt,
        device=pipe.device,
        num_images_per_prompt=1,
        max_sequence_length=512
    )
    is_text_broken = check_tensor("Text Embeddings", prompt_embeds)

    if is_text_broken:
        print("\nğŸš¨ è¯Šæ–­ç»“è®ºï¼šã€Text Encoderã€‘åœ¨ FP16 ä¸‹æº¢å‡ºï¼")
        print("ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼šå¿…é¡»å°† Text Encoder è½¬ä¸º FP32ã€‚")
        print("   ä»£ç ï¼špipe.text_encoder.to(dtype=torch.float32)")
        # å¦‚æœè¿™é‡Œå°±æŒ‚äº†ï¼Œä¸ºäº†æµ‹è¯•åé¢ï¼Œæˆ‘ä»¬å¼ºè¡Œä¿®å¤ä¸€ä¸‹ç»§ç»­è·‘
        # pipe.text_encoder.to(dtype=torch.float32)
        # (ä½†åœ¨è¯Šæ–­è„šæœ¬é‡Œæˆ‘ä»¬å…ˆæš‚åœï¼Œè®©ä½ çœ‹æ¸…æ¥šç»“æœ)
        exit()
    else:
        print("âœ… Text Encoder çœ‹èµ·æ¥æ²¡é—®é¢˜ï¼Œç»§ç»­æ£€æŸ¥ä¸‹ä¸€æ­¥...")

except Exception as e:
    print(f"Text Encoder è¿è¡Œå‡ºé”™: {e}")

# ==============================================================================
# ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥ DiT (Transformer) æ¨ç†è¿‡ç¨‹
# ==============================================================================
print("\nğŸ” æ­¥éª¤ 2: æ£€æŸ¥ DiT é€æ­¥å»å™ªè¿‡ç¨‹...")


# å®šä¹‰ä¸€ä¸ªå›è°ƒå‡½æ•°ï¼Œç›‘æ§æ¯ä¸€æ­¥çš„ Latents
def callback_monitor(pipe, step, timestep, callback_kwargs):
    latents = callback_kwargs.get("latents")
    # åªæ£€æŸ¥ç¬¬ä¸€æ­¥å’Œä¸­é—´å‡ æ­¥ï¼Œé¿å…åˆ·å±
    if step % 5 == 0:
        is_broken = check_tensor(f"DiT Step {step}", latents)
        if is_broken:
            print(f"\nğŸš¨ è¯Šæ–­ç»“è®ºï¼šã€DiT (Transformer)ã€‘åœ¨ç¬¬ {step} æ­¥æº¢å‡ºï¼")
            print("ğŸ’¡ åŸå› ï¼šFP16 èŒƒå›´ä¸å¤Ÿï¼Œæˆ–è€…è¾“å…¥æ•°æ®å·²ç»æ˜¯ NaNã€‚")
            print("ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼šå¦‚æœ Text Encoder æ²¡é—®é¢˜ï¼Œé‚£è¯´æ˜ DiT ä¹Ÿå¿…é¡»è½¬ FP32 (ä½†è¿™åœ¨ V100 ä¸Šå¯èƒ½æ˜¾å­˜ä¸å¤Ÿ)ã€‚")
            raise ValueError("DiT Output is NaN, stopping generation.")
    return callback_kwargs


# å‡†å¤‡æ•°æ®
width, height = 512, 512
generator = torch.Generator(device="cpu").manual_seed(42)

try:
    # å¼ºåˆ¶ VAE ç”¨ FP32 (æˆ‘ä»¬å·²çŸ¥ VAE è‚¯å®šæœ‰é—®é¢˜ï¼Œå…ˆæ’é™¤å®ƒï¼Œä¸“å¿ƒæµ‹ DiT)
    pipe.vae.to(dtype=torch.float32)

    print("   (æ³¨ï¼šå·²ä¸´æ—¶å°† VAE è®¾ä¸º FP32 ä»¥æ’é™¤å¹²æ‰°ï¼Œä¸“å¿ƒç›‘æµ‹ DiT)")

    image = pipe(
        prompt=prompt,
        negative_prompt=" ",
        width=width,
        height=height,
        num_inference_steps=10,  # åªè·‘10æ­¥å¿«é€Ÿæµ‹è¯•
        true_cfg_scale=4.0,
        generator=generator,
        callback_on_step_end=callback_monitor  # <--- æ’å…¥æ¢é’ˆ
    ).images[0]

    print("\nâœ… è¯Šæ–­ç»“è®ºï¼šDiT (Transformer) åœ¨ FP16 ä¸‹è¿è¡Œæ­£å¸¸ï¼")
    print("ğŸ‰ å¦‚æœæœ€ç»ˆå›¾ç‰‡è¿˜æ˜¯é»‘çš„ï¼Œé‚£æ˜¯ VAE çš„é—®é¢˜ (ä½†æˆ‘ä»¬å·²ç»ä¿®äº† VAE)ã€‚")

except ValueError as e:
    print("æ¨ç†è¢«ä¸­æ–­ã€‚")
except Exception as e:
    print(f"æ¨ç†å‡ºé”™: {e}")